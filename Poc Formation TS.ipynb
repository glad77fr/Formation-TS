{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POC Power BI TS Formation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from os import path\n",
    "import glob\n",
    "import xlsxwriter\n",
    "import openpyxl "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Déclaration des fonctions et classes exploitées dans le code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Datamanagement:\n",
    "    def __init__(self):\n",
    "        self.source = {} # Contient le nom et la localisation des fichiers sources\n",
    "        self.dim = {} # Contient le nom et les dataframes des tables de dimension\n",
    "        self.fact = {} # Contient le nom et les dataframes liés aux tables de faits\n",
    "        self.changed_keys = {}\n",
    "    \n",
    "    def import_csv(self, filename, engine_val=None, encoding_val='utf-8', sep_val=';',low_memory_val=False):\n",
    "        self.source[filename[:-4]] = pd.read_csv(r'Data/'+ filename, engine=engine_val, encoding=encoding_val, sep=sep_val, low_memory=low_memory_val)\n",
    "        return self.source[filename[:-4]]\n",
    "    \n",
    "    def update_key(self, changed_keys, filename):\n",
    "        self.changed_keys[filename] = changed_keys\n",
    "        self.source[filename].rename(columns=changed_keys , inplace=True)\n",
    "        return self.source[filename]\n",
    "    \n",
    "    def import_dim(self,dimname, dimdataframe):\n",
    "        self.dim[dimname]=dimdataframe\n",
    "    \n",
    "    def export(self):\n",
    "        for key, value in self.dim.items():\n",
    "            location = \"Transformed data\"\n",
    "            file_name = str(key) + '.csv'\n",
    "            location = os.path.join(location, file_name)  \n",
    "            value.to_csv(location, encoding='utf-8', index=False)\n",
    "            \n",
    "        for key, value in self.fact.items():\n",
    "            location = \"Transformed data\"\n",
    "            file_name = str(key) + '.csv'\n",
    "            location = os.path.join(location, file_name)  \n",
    "            value.to_csv(location, encoding='utf-16', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Génération/Mise à jour du fichier setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3249: DtypeWarning: Columns (0,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "def import_data():\n",
    "    all_dir = glob.glob(\"Data/*.csv\")    \n",
    "    all_files_name = [x[5:] for x in all_dir]\n",
    "    all_files_name = [x[:-4] for x in all_files_name]\n",
    "    df_files_col = pd.DataFrame()\n",
    "    p = 1\n",
    "    \n",
    "    for dir in all_dir:\n",
    "        df = pd.read_csv(dir, encoding='utf-8', sep=';')\n",
    "        \n",
    "        for i, col in enumerate(df.columns):\n",
    "            df_files_col.at[p, 'Nom fichier source'] = dir[5:-4]\n",
    "            df_files_col.at[p,'Nom champ source'] = col\n",
    "            df_files_col.at[p,'Type'] = str(df[col].dtypes)\n",
    "            df_files_col.at[p,'Synthèse'] = str(df[col].describe())\n",
    "            df_files_col.at[p, 'Répertoire'] = dir\n",
    "            p = p + i\n",
    "    \n",
    "    df_dir_files = df_files_col.copy()\n",
    "    df_dir_files = df_dir_files[[\"Nom fichier source\", \"Répertoire\"]].drop_duplicates()\n",
    "    \n",
    "    if path.exists(\"Settings & documentation\\Settings.xlsx\"):\n",
    "        pass\n",
    "\n",
    "    else:\n",
    "\n",
    "        writer = pd.ExcelWriter(r\"Settings & documentation\\Settings.xlsx\", engine='xlsxwriter')\n",
    "        workbook  = writer.book\n",
    "        df_dir_files.to_excel(writer, sheet_name='Fichiers Source', index=False)\n",
    "        \n",
    "        df_files_col[['Nom fichier source', 'Nom champ source', 'Type', 'Synthèse' ]].to_excel(writer, sheet_name='Fichiers et colonnes source', index=False)\n",
    "                \n",
    "        worksheet_FCS = writer.sheets[\"Fichiers et colonnes source\"]\n",
    "        worksheet_FS = writer.sheets[\"Fichiers Source\"]\n",
    "        #worksheet1 = workbook.add_worksheet(\"Mapping données\")\n",
    "        \n",
    "        cell_format_FCS = workbook.add_format() \n",
    "        cell_format_FCS.set_text_wrap()\n",
    "        cell_format_FCS.set_align('center')\n",
    "        cell_format_FCS.set_align('vcenter')\n",
    "        \n",
    "        cell_format_FS = workbook.add_format()    \n",
    "        cell_format_FS.set_align('left')\n",
    "                \n",
    "        worksheet_FCS.set_column('A:B', 30, cell_format_FCS)\n",
    "        worksheet_FCS.set_column('C:C', 15, cell_format_FCS)\n",
    "        worksheet_FCS.set_column('D:D', 25, cell_format_FCS)\n",
    "        worksheet_FS.set_column('A:A', 40, cell_format_FS)\n",
    "        worksheet_FS.set_column('B:B', 60, cell_format_FS)\n",
    "\n",
    "        writer.save()\n",
    "        workbook.close()\n",
    "\n",
    "# Fonction créant la feuille Mapping dim dans le fichier Settings\n",
    "# Cette feuille contient l'ensemble des valeurs de dimension et permet de réaliser un mapping pour changer le nom des attributs\n",
    "\n",
    "def add_sheet_mapcol(DicDataframe):\n",
    "    \n",
    "    df = pd.DataFrame(columns=[\"Nom dimension\", \"Nom colonne\"],data=[])\n",
    "    \n",
    "    for key, value in DicDataframe.items():        \n",
    "        #if len(key) >= 3:\n",
    "        #    if key[:3] == \"dim\":\n",
    "        for i, col in enumerate(value.columns):\n",
    "            df.at[i, \"Nom dimension\"] = key\n",
    "            df.at[i, \"Nom colonne\"] = col\n",
    "            df.at[i, \"Nouveau nom\"] = \"\"\n",
    "            df.at[i, \"A mapper\"] = \"Non\"                \n",
    "      \n",
    "    workbook1 = openpyxl.load_workbook(r\"Settings & documentation\\Settings.xlsx\")  \n",
    "    writer = pd.ExcelWriter(r\"Settings & documentation\\Settings.xlsx\", engine='openpyxl')\n",
    "    writer.book = workbook1\n",
    "    df.to_excel(writer, sheet_name=\"Mapping dim colonne\",engine='openpyxl',index=False)     \n",
    "    writer.save()\n",
    "    writer.close()\n",
    "    \n",
    "    workbook1 = openpyxl.load_workbook(r\"Settings & documentation\\Settings.xlsx\")\n",
    "    writer = pd.ExcelWriter(r\"Settings & documentation\\Settings.xlsx\", engine='openpyxl')\n",
    "    writer.book = workbook1\n",
    "    workbook1[\"Mapping dim colonne\"].column_dimensions[\"A\"].width = 20\n",
    "    workbook1[\"Mapping dim colonne\"].column_dimensions[\"B\"].width = 20\n",
    "    workbook1[\"Mapping dim colonne\"].column_dimensions[\"C\"].width = 20\n",
    "    \n",
    "    writer.save()\n",
    "    writer.close()\n",
    "    \n",
    "import_data()\n",
    "\n",
    "my_data = Datamanagement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction permettant d'exporter un dataframe vers un onglet de setting avec un formatage automatique des colonnes\n",
    "def export_to_settings(dataframe, sheetname):\n",
    "    letters = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "    numbers = range(0,26,1)\n",
    "    dic_letters = {} # Dictionnaire contenant les lettres de l'alphabet    \n",
    "    val_max = [] # Liste contenant la taille des valeurs les plus longues\n",
    "    \n",
    "    # Création d'un dictionnaire stockant les lettres de l'alphabet et leur position afin d'alimenter les fonctions openpyxl\n",
    "    for i in range(len(numbers)): \n",
    "        dic_letters[numbers[i]] = letters[i]\n",
    "    \n",
    "    # Alimentation de val_max\n",
    "    for col in dataframe.columns:\n",
    "        max = (dataframe[col].astype(str)).str.len().max()\n",
    "        #max = dataframe[col].str.len().max()\n",
    "        if max != 0:\n",
    "            val_max.append(int(max)+1)\n",
    "        else:\n",
    "            val_max.append(15)\n",
    "            \n",
    "   # Ouverture du fichier setting et création de l'onglet sheetname\n",
    "    workbook1 = openpyxl.load_workbook(r\"Settings & documentation\\Settings.xlsx\")  \n",
    "    writer = pd.ExcelWriter(r\"Settings & documentation\\Settings.xlsx\", engine='openpyxl')\n",
    "    writer.book = workbook1\n",
    "    dataframe.to_excel(writer, sheet_name= sheetname, engine='openpyxl', index=False)     \n",
    "    writer.save()\n",
    "    writer.close()\n",
    "    \n",
    "   # Réouverture du fichier setting \n",
    "    workbook1 = openpyxl.load_workbook(r\"Settings & documentation\\Settings.xlsx\")  \n",
    "    writer = pd.ExcelWriter(r\"Settings & documentation\\Settings.xlsx\", engine='openpyxl')\n",
    "    writer.book = workbook1\n",
    "    \n",
    "    # Aliemntation du fichier excel avec les données du dataframe\n",
    "    #for i, width in enumerate(get_col_widths(dataframe)):\n",
    "    print(val_max)\n",
    "    for i, width in enumerate(val_max):\n",
    "        workbook1[sheetname].column_dimensions[dic_letters[i]].width = width\n",
    "    \n",
    "    # Sauvegarde et fermeture du fichier excel\n",
    "    writer.save()\n",
    "    writer.close()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction mapping des noms de colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction transformant le nom des colonnes suivant le mapping effectué dans l'onglet Mapping dim colonne du fichier setting\n",
    "# Entrée: Dictionnaire key: Nom dataframe  Value : Dataframe\n",
    "# Sortie un dictionnaire \"nom\"/Dataframe avec les valeurs des colonnes actualisées suivant l'onglet de mapping \"Mapping dim colonne\" du fichier settings\n",
    "\n",
    "def map_col(dict_dataframe):\n",
    "    md = pd.read_excel(r\"Settings & documentation\\Settings.xlsx\", sheet_name=\"Mapping dim colonne\")\n",
    "    mdf = md[\"Nom dimension\"].unique()\n",
    "    dic_map = {}\n",
    "    for dim in mdf:\n",
    "        map = md.loc[(md[\"Nom dimension\"] == dim ) & (md[\"Nouveau nom\"].notnull()== True),[\"Nom colonne\",\"Nouveau nom\"]]\n",
    "        map.reset_index(drop=True, inplace=True)\n",
    "            \n",
    "        for i, val in enumerate(map.iterrows()):           \n",
    "            dict_dataframe[dim].rename(columns={map.at[i, \"Nom colonne\"]:map.at[i,\"Nouveau nom\"]},inplace=True)\n",
    "     \n",
    "    return dict_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction générant une liste des valeurs des champs à mapper. Chaque type de valeur sera extraite.\n",
    "\n",
    "def mapp_data(dict_dataframe):\n",
    "    result = pd.DataFrame()\n",
    "    \n",
    "    try:       \n",
    "        to_mapp_data = pd.read_excel(r'Settings & documentation\\Settings.xlsx', sheet_name=\"Mapping données\") # Lecture de la feuille Mapping données\n",
    "        to_mapp_data = to_mapp_data.loc[to_mapp_data[\"Valeurs cible\"] != '']\n",
    "        to_mapp_data.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        if to_mapp_data.empty == False:\n",
    "            for i, val in enumerate(to_mapp_data.iterrows()):\n",
    "                dict_dataframe[to_mapp_data.at[i,\"Table\"]][to_mapp_data.at[i,\"Colonnes\"]].replace(to_replace =to_mapp_data.at[i,\"Valeurs actuelles\"], \n",
    "                 value = to_mapp_data.at[i,\"Valeurs cible\"], inplace=True)\n",
    "            \n",
    "    except:\n",
    "            mapp_col = pd.read_excel(r'Settings & documentation\\Settings.xlsx', sheet_name=\"Mapping dim colonne\")\n",
    "            mapp_col = mapp_col.loc[mapp_col[\"A mapper\"] == \"Oui\", [\"Nom dimension\", \"Nom colonne\", \"Nouveau nom\"]]\n",
    "            mapp_col[\"Colonne\"] = \"\"\n",
    "            mapp_col.reset_index(inplace=True, drop=True)\n",
    "            mapp_val = pd.DataFrame(columns=[\"Table\", \"Colonnes\", \"Valeurs actuelles\", \"Valeurs cible\"])\n",
    "            p=1\n",
    "            if mapp_col.empty == False:\n",
    "                for i, val in enumerate(mapp_col.iterrows()):\n",
    "                    if str(mapp_col.at[i, \"Nouveau nom\"]) != \"nan\":\n",
    "                        mapp_col.at[i,\"Colonne\"] = mapp_col.at[i, \"Nouveau nom\"]\n",
    "                    else:\n",
    "                         mapp_col.at[i,\"Colonne\"] = mapp_col.at[i, \"Nom colonne\"]\n",
    "\n",
    "                for i,val in enumerate(mapp_col[[\"Nom dimension\", \"Colonne\"]].iterrows()):\n",
    "                    \n",
    "                    if (dict_dataframe[mapp_col.at[i, \"Nom dimension\"]][mapp_col.at[i, \"Colonne\"]]).empty == False:\n",
    "                        list_val = (dict_dataframe[mapp_col.at[i, \"Nom dimension\"]][mapp_col.at[i, \"Colonne\"]]).unique()\n",
    "                        nom_col = mapp_col.at[i, \"Colonne\"]\n",
    "                        nom_table = mapp_col.at[i, \"Nom dimension\"]\n",
    "\n",
    "                    if len(list_val) != 0:\n",
    "                        for i, val in enumerate(list_val):                           \n",
    "                            mapp_val.at[p,\"Table\"] = nom_table\n",
    "                            mapp_val.at[p,\"Colonnes\"] = nom_col\n",
    "                            mapp_val.at[p,\"Valeurs actuelles\"] = val\n",
    "                            mapp_val.at[p,\"Valeurs cible\"] = \"\"\n",
    "                            p += 1\n",
    "                            \n",
    "            if mapp_val.empty:                \n",
    "                pass            \n",
    "            else:\n",
    "                export_to_settings(mapp_val,\"Mapping données\")            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Import des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 906 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### Ajouter les tables à intégrer ici\n",
    "tcw = my_data.import_csv('191119_TrainingCollectiveWishes.csv') # Demandes collectives non affectées à un plan de formation\n",
    "tiw = my_data.import_csv('191119_TrainingIndividualWishes.csv') # Demandes individuelles non affectées à un plan de formation\n",
    "tp = my_data.import_csv('191119_TrainingPlan.csv') # Plans de formation\n",
    "tpcw = my_data.import_csv('191119_TrainingPlanCollectiveWishes.csv') # Demande de formation collectives prises en charge dans un plan de formation\n",
    "tpiw = my_data.import_csv('191119_TrainingPlanIndividualWishes.csv') # Demande de formation individuelles prises en charge dans un plan de formation\n",
    "tr = my_data.import_csv('191119_TrainingRegister.csv') # Table recensant les inscription aux sessions de formation \n",
    "ts = my_data.import_csv('191119_TrainingSessions.csv') # Table recensant les sessions de formation \n",
    "tsc = my_data.import_csv('191119_TrainingStageCost.csv') # Table contenant les coûts des stages\n",
    "tsv2 = my_data.import_csv('191119_TrainingStagev2.csv') # Table contenant les stages\n",
    "emp = my_data.import_csv('191119_Employees.csv') # Table maître employé\n",
    "empc = my_data.import_csv('191119_EmployementContract.csv') # Table contrat employé\n",
    "indO = my_data.import_csv('191119_IndividualOrganization.csv') # Table organisation employé\n",
    "indpp =my_data.import_csv('191119_IndivPPCsNew.csv') # ?\n",
    "#setting = pd.read_excel(r'Data/Settings.xlsx', sheets=\"Mapp_data\") # Table de paramétrage servant à mapper les données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Renommage des clés fonctionnelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 39 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ts = my_data.update_key({'clientcode':'SessionID', 'coursecode':'FormationID', 'startdate':'SessionDate'},'191119_TrainingSessions')\n",
    "tsv2 = my_data.update_key({'clientcode':'SessionID'},'191119_TrainingStagev2')\n",
    "tr = my_data.update_key({'clientcode':'SessionID', 'traineusername':'USERNAME'}, '191119_TrainingRegister')\n",
    "tp = my_data.update_key({'plancode':'PlanID'}, '191119_TrainingPlan')\n",
    "emp = my_data.update_key({'username':'USERNAME'}, '191119_Employees')\n",
    "tcw = my_data.update_key({'clientcode':'WishID','coursecode':'FormationID','username':'USERNAME'}, '191119_TrainingCollectiveWishes')\n",
    "tiw = my_data.update_key({'username':'USERNAME', 'employeenumber':'ZY00.MATCLE', 'clientcode':'WishID', 'coursecode':'FormationID'},'191119_TrainingIndividualWishes')\n",
    "tpcw = my_data.update_key({'plan_code':'PlanID', 'wish_code':'WishID'}, '191119_TrainingPlanCollectiveWishes')\n",
    "tpiw = my_data.update_key({'plan_code':'PlanID', 'wish_code':'WishID'} ,'191119_TrainingPlanIndividualWishes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Alimentation des dictionnaires contenant les colonnes et dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "my_dict_dataframe = {\"tcw\": tcw, \"tiw\": tiw, \"tp\" : tp, \"tpcw\" : tpcw, \"tr\" : tr, \"ts\" : ts, \"tsc\" : tsc, \"tsv2\" : tsv2, \"emp\" : emp,\n",
    "           \"empc\" : empc, \"indO\": indO, \"indpp\": indpp}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Creation des tables de dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de la table dimension demandes de formations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 92 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Fusion des tables TrainingCollectiveWishes et TrainingIndividualWishes\n",
    "dim_wish = tcw.append(tiw,sort=True)\n",
    "dim_wish.reset_index(drop=True, inplace=True)\n",
    "dim_wish[\"Wish_key\"] = dim_wish.index\n",
    "dim_wish.loc[dim_wish.nbtrainees.isna(), \"nbtrainees\"] = 1\n",
    "#dim_wish = df_mapp(dim_wish)\n",
    "my_data.import_dim(\"dim_wish_table\", dim_wish)\n",
    "\n",
    "#y_data.dim[\"dim_wish_table\"] = dim_wish\n",
    "#my_dict_dataframe[\"dim_wish_table\"]= dim_wish\n",
    "#wish_table.to_excel(r'Transformed data\\wish_table.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traitement du mapping des colonnes et des valeurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['dim_wish_table'])\n",
      "Wall time: 502 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops\\__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Verification si la colonne Mapping dim existe dans le fichier setting, si non on va la créer\n",
    "try:\n",
    "    pd.read_excel(r'Settings & documentation\\Settings.xlsx', sheet_name=\"Mapping dim colonne\")\n",
    "    Mapp_sheet = True    \n",
    "except:\n",
    "    Mapp_sheet = False\n",
    "    \n",
    "if Mapp_sheet == True:    \n",
    "    pass\n",
    "else:\n",
    "    add_sheet_mapcol(my_data.dim)\n",
    "\n",
    "#my_dict_dataframe = map_col(my_data.dim)\n",
    "#mapp_data(my_dict_dataframe)\n",
    "\n",
    "# Mapping des données\n",
    "\n",
    "my_data.dim = map_col(my_data.dim)\n",
    "mapp_data(my_data.dim)\n",
    "\n",
    "print(my_data.dim.keys())\n",
    "      \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Création des tables de fait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table de fait demande de formation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#wish_fact = dim_wish[[\"Wish_key\", \"nombre de formés\"]].copy()\n",
    "#dim_wish.loc[:, \"Nb_demandes\"]= 1\n",
    "\n",
    "#my_dict_dataframe[\"wish_fact\"] = wish_fact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export des données vers le répertoire Transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 821 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#for key, value in my_dict_dataframe.items():\n",
    " #       location = \"Transformed data\"\n",
    "  #      file_name = str(key) + '.csv'\n",
    "   #     location = os.path.join(location, file_name)  \n",
    "    #    value.to_csv(location, encoding='utf16', index=False)\n",
    "    \n",
    "my_data.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
