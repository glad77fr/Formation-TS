{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POC Power BI TS Formation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from os import path\n",
    "import glob\n",
    "import xlsxwriter\n",
    "import openpyxl # 3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Déclaration des fonctions et classes exploitées dans le code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Datamanagement:\n",
    "    def __init__(self):\n",
    "        self.source = {} # Dictionnaire contenant le nom et la localisation des fichiers sources\n",
    "        self.dim = {} # Dictionnaire contenant le nom et les dataframes des tables de dimension\n",
    "        self.fact = {} # Dictionnaire contenant le nom et les dataframes liés aux tables de faits\n",
    "        self.changed_keys = {}\n",
    "    \n",
    "    def import_csv(self, filename, engine_val=None, encoding_val='utf-8', sep_val=';',low_memory_val=False):\n",
    "        self.source[filename[:-4]] = pd.read_csv(r'Data/'+ filename, engine=engine_val, encoding=encoding_val, sep=sep_val, low_memory=low_memory_val)\n",
    "        return self.source[filename[:-4]]\n",
    "    \n",
    "    def update_key(self, changed_keys, filename):\n",
    "        self.changed_keys[filename] = changed_keys\n",
    "        self.source[filename].rename(columns=changed_keys , inplace=True)\n",
    "        return self.source[filename]\n",
    "    \n",
    "    def import_dim(self,dimname, dimdataframe):\n",
    "        self.dim[dimname]=dimdataframe\n",
    "        \n",
    "    def import_fact(self,factname, factdataframe):\n",
    "        self.fact[factname] = factdataframe\n",
    "    \n",
    "    def export(self):\n",
    "        for key, value in self.dim.items():\n",
    "            location = \"Transformed data\"\n",
    "            file_name = str(key) + '.csv'\n",
    "            location = os.path.join(location, file_name)  \n",
    "            value.to_csv(location, encoding='utf-8', index=False)\n",
    "            \n",
    "        for key, value in self.fact.items():\n",
    "            location = \"Transformed data\"\n",
    "            file_name = str(key) + '.csv'\n",
    "            location = os.path.join(location, file_name)  \n",
    "            value.to_csv(location, encoding='utf-16', index=False)\n",
    "            \n",
    "    def import_data(self):\n",
    "# Fonction générant le fichier setting lors du premier chargement si ce dernier n'existe pas\n",
    "# Etape 1 skockage du nom des fichiers présents dans data\n",
    "# Etape 2 lecture des fichiers présents dans data et extraction des colonnes ainsi que des informations liées à la qualité de données\n",
    "# Etape 3 vérification si le fichier Settings.xlsx existe, s'il existe, il faut éventuellement le modifier avec les nouvelles informations, sinon le créer\n",
    "        \n",
    "        #Etape 1: skockage du nom des fichiers présents dans data\n",
    "        all_dir = glob.glob(\"Data/*.csv\")    \n",
    "        all_files_name = [x[5:] for x in all_dir]\n",
    "        all_files_name = [x[:-4] for x in all_files_name]\n",
    "        df_files_col = pd.DataFrame()\n",
    "        p = 1\n",
    "\n",
    "        #Etape 2 lecture des fichiers présents dans data et extraction des colonnes ainsi que des informations liées à la qualité de données\n",
    "        for dir in all_dir:\n",
    "            df = pd.read_csv(dir, encoding='utf-8', sep=';')\n",
    "\n",
    "            for i, col in enumerate(df.columns):\n",
    "                df_files_col.at[p, 'Nom fichier source'] = dir[5:-4]\n",
    "                df_files_col.at[p,'Nom champ source'] = col\n",
    "                df_files_col.at[p,'Type'] = str(df[col].dtypes)\n",
    "                df_files_col.at[p,'Synthèse'] = str(df[col].describe())\n",
    "                df_files_col.at[p, 'Répertoire'] = dir\n",
    "                df_files_col.at[p, \"Date ajout\"] = str(datetime.date(datetime.now()))\n",
    "                df_files_col.at[p, \"Date modification\"] = str(datetime.date(datetime.now()))\n",
    "                p = p + i\n",
    "\n",
    "        df_dir_files = df_files_col.copy()\n",
    "        df_dir_files = df_dir_files[[\"Nom fichier source\", \"Répertoire\", \"Date ajout\", \"Date modification\"]].drop_duplicates()\n",
    "\n",
    "        if path.exists(\"Settings & documentation\\Settings.xlsx\"):\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "            writer = pd.ExcelWriter(r\"Settings & documentation\\Settings.xlsx\", engine='xlsxwriter')\n",
    "            workbook  = writer.book\n",
    "            df_dir_files.to_excel(writer, sheet_name='Fichiers Source', index=False)\n",
    "\n",
    "            df_files_col[['Nom fichier source', 'Nom champ source', 'Type', 'Synthèse']].to_excel(writer, sheet_name='Fichiers et colonnes source', index=False)\n",
    "\n",
    "            worksheet_FCS = writer.sheets[\"Fichiers et colonnes source\"]\n",
    "            worksheet_FS = writer.sheets[\"Fichiers Source\"]\n",
    "            #worksheet1 = workbook.add_worksheet(\"Mapping données\")\n",
    "\n",
    "            cell_format_FCS = workbook.add_format() \n",
    "            cell_format_FCS.set_text_wrap()\n",
    "            cell_format_FCS.set_align('center')\n",
    "            cell_format_FCS.set_align('vcenter')\n",
    "\n",
    "            cell_format_FS = workbook.add_format()    \n",
    "            cell_format_FS.set_align('left')\n",
    "\n",
    "            worksheet_FCS.set_column('A:B', 30, cell_format_FCS)\n",
    "            worksheet_FCS.set_column('C:C', 15, cell_format_FCS)\n",
    "            worksheet_FCS.set_column('D:D', 25, cell_format_FCS)\n",
    "            worksheet_FS.set_column('A:A', 40, cell_format_FS)\n",
    "            worksheet_FS.set_column('B:B', 60, cell_format_FS)\n",
    "            worksheet_FS.set_column('C:C', 20, cell_format_FS)\n",
    "            worksheet_FS.set_column('D:D', 20, cell_format_FS)\n",
    "            writer.save()\n",
    "            workbook.close()\n",
    "\n",
    "    def add_sheet_mapcol(self,DicDataframe=None):\n",
    "# Fonction créant la feuille Mapping dim dans le fichier Settings\n",
    "# Cette feuille contient l'ensemble des valeurs de dimension, elle permet de réaliser un mapping pour changer le nom des attributs\n",
    "\n",
    "        if DicDataframe == None:\n",
    "            DicDataframe = self.dim           \n",
    "            \n",
    "        df = pd.DataFrame(columns=[\"Nom dimension\", \"Nom colonne\"],data=[])\n",
    "\n",
    "        for key, value in DicDataframe.items():        \n",
    "\n",
    "            for i, col in enumerate(value.columns):\n",
    "                df.at[i, \"Nom dimension\"] = key\n",
    "                df.at[i, \"Nom colonne\"] = col\n",
    "                df.at[i, \"Nouveau nom\"] = \"\"\n",
    "                df.at[i, \"A mapper\"] = \"Non\"                \n",
    "\n",
    "        workbook1 = openpyxl.load_workbook(r\"Settings & documentation\\Settings.xlsx\")  \n",
    "        writer = pd.ExcelWriter(r\"Settings & documentation\\Settings.xlsx\", engine='openpyxl')\n",
    "        writer.book = workbook1\n",
    "        df.to_excel(writer, sheet_name=\"Mapping dim colonne\",engine='openpyxl',index=False)     \n",
    "        writer.save()\n",
    "        writer.close()\n",
    "\n",
    "        workbook1 = openpyxl.load_workbook(r\"Settings & documentation\\Settings.xlsx\")\n",
    "        writer = pd.ExcelWriter(r\"Settings & documentation\\Settings.xlsx\", engine='openpyxl')\n",
    "        writer.book = workbook1\n",
    "        workbook1[\"Mapping dim colonne\"].column_dimensions[\"A\"].width = 20\n",
    "        workbook1[\"Mapping dim colonne\"].column_dimensions[\"B\"].width = 20\n",
    "        workbook1[\"Mapping dim colonne\"].column_dimensions[\"C\"].width = 20\n",
    "\n",
    "        writer.save()\n",
    "        writer.close()\n",
    "    \n",
    "    def map_col(self):\n",
    "        \n",
    "# Fonction transformant le nom des colonnes suivant le mapping effectué dans l'onglet Mapping dim colonne du fichier setting\n",
    "# Entrée: Dictionnaire key: Nom dataframe  Value : Dataframe\n",
    "# Sortie un dictionnaire \"nom\"/Dataframe avec les valeurs des colonnes actualisées suivant l'onglet de mapping \"Mapping dim colonne\" du fichier settings\n",
    "\n",
    "        dict_dataframe = self.dim\n",
    "        md = pd.read_excel(r\"Settings & documentation\\Settings.xlsx\", sheet_name=\"Mapping dim colonne\")\n",
    "        mdf = md[\"Nom dimension\"].unique()\n",
    "        dic_map = {}\n",
    "        \n",
    "        for dim in mdf:\n",
    "            map = md.loc[(md[\"Nom dimension\"] == dim ) & (md[\"Nouveau nom\"].notnull()== True),[\"Nom colonne\",\"Nouveau nom\"]]\n",
    "            map.reset_index(drop=True, inplace=True)\n",
    "\n",
    "            for i, val in enumerate(map.iterrows()):           \n",
    "                dict_dataframe[dim].rename(columns={map.at[i, \"Nom colonne\"]:map.at[i,\"Nouveau nom\"]},inplace=True)\n",
    "\n",
    "        my_dim = dict_dataframe    \n",
    "    \n",
    "    def export_to_settings(self, dataframe, sheetname, position = None):\n",
    "# Fonction permettant d'exporter un dataframe vers un onglet de setting avec un formatage automatique des colonnes\n",
    "# Paramètres: \n",
    "# dataframe: correspond au dataframe à importer,\n",
    "# sheetname: correspond au nom de la feuille cible qui sera remplacées,\n",
    "# position: permet de choisir la position de la feuille modifiée dans le fichier excel\n",
    "   \n",
    "        letters = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "        numbers = range(0,26,1)\n",
    "        dic_letters = {} # Dictionnaire contenant les lettres de l'alphabet    \n",
    "        val_max = [] # Liste contenant la taille des valeurs les plus longues\n",
    "\n",
    "        # Création d'un dictionnaire stockant les lettres de l'alphabet et leur position afin d'alimenter les fonctions openpyxl\n",
    "        for i in range(len(numbers)): \n",
    "            dic_letters[numbers[i]] = letters[i]\n",
    "\n",
    "        # Alimentation de val_max\n",
    "        for col in dataframe.columns:\n",
    "            max = (dataframe[col].astype(str)).str.len().max()        \n",
    "            if max != 0:\n",
    "                val_max.append(int(max)+1)\n",
    "            else:\n",
    "                val_max.append(15)\n",
    "\n",
    "       # Ouverture du fichier setting et création de l'onglet sheetname\n",
    "    \n",
    "        workbook1 = openpyxl.load_workbook(r\"Settings & documentation\\Settings.xlsx\")  \n",
    "        writer = pd.ExcelWriter(r\"Settings & documentation\\Settings.xlsx\", engine='openpyxl')\n",
    "        writer.book = workbook1\n",
    "        list_sheet = workbook1.get_sheet_names() # Récupère la liste des feuilles\n",
    "\n",
    "        if sheetname in list_sheet: # Si l'onglet existe déjà on va le supprimer pour le remplacer\n",
    "            std = workbook1.get_sheet_by_name(sheetname)\n",
    "            workbook1.remove_sheet(std)\n",
    "\n",
    "        dataframe.to_excel(writer, sheet_name= sheetname, engine='openpyxl', index=False)     \n",
    "        writer.save()\n",
    "        writer.close()\n",
    "\n",
    "        # Gère la position de la feuille\n",
    "\n",
    "        workbook1 = openpyxl.load_workbook(r\"Settings & documentation\\Settings.xlsx\")  \n",
    "        writer = pd.ExcelWriter(r\"Settings & documentation\\Settings.xlsx\", engine='openpyxl')\n",
    "        writer.book = workbook1\n",
    "\n",
    "        if position == None:        \n",
    "            pos = len(list_sheet) - 1\n",
    "        else:\n",
    "            pos = position\n",
    "\n",
    "        sheets = workbook1._sheets\n",
    "\n",
    "        sheet = sheets.pop(len(list_sheet) - 1)\n",
    "        sheets.insert(pos, sheet)\n",
    "\n",
    "        writer.save()\n",
    "        writer.close()\n",
    "\n",
    "       # Réouverture du fichier setting\n",
    "    \n",
    "        workbook1 = openpyxl.load_workbook(r\"Settings & documentation\\Settings.xlsx\")  \n",
    "        writer = pd.ExcelWriter(r\"Settings & documentation\\Settings.xlsx\", engine='openpyxl')\n",
    "        writer.book = workbook1\n",
    "\n",
    "        # Alimentation du fichier excel avec les données du dataframe\n",
    "\n",
    "        for i, width in enumerate(val_max):\n",
    "            if width < 11:\n",
    "                workbook1[sheetname].column_dimensions[dic_letters[i]].width = 12\n",
    "            else:\n",
    "                workbook1[sheetname].column_dimensions[dic_letters[i]].width = width\n",
    "\n",
    "        # Sauvegarde et fermeture du fichier excel\n",
    "        \n",
    "        writer.save()\n",
    "        writer.close()    \n",
    "    \n",
    "    def mapp_data(self):\n",
    "        result = pd.DataFrame()\n",
    "\n",
    "        try:       \n",
    "            to_mapp_data = pd.read_excel(r'Settings & documentation\\Settings.xlsx', sheet_name=\"Mapping données\") # Lecture de la feuille Mapping données\n",
    "            to_mapp_data = to_mapp_data.loc[to_mapp_data[\"Valeurs cible\"].isna == False]\n",
    "            to_mapp_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "            if to_mapp_data.empty == False:\n",
    "                for i, val in enumerate(to_mapp_data.iterrows()):\n",
    "                    self.dim[to_mapp_data.at[i,\"Table\"]][to_mapp_data.at[i,\"Colonnes\"]].replace(to_replace =to_mapp_data.at[i,\"Valeurs actuelles\"], \n",
    "                     value = to_mapp_data.at[i,\"Valeurs cible\"], inplace=True)\n",
    "        except:\n",
    "                mapp_col = pd.read_excel(r'Settings & documentation\\Settings.xlsx', sheet_name=\"Mapping dim colonne\")\n",
    "                mapp_col = mapp_col.loc[mapp_col[\"A mapper\"] == \"Oui\", [\"Nom dimension\", \"Nom colonne\", \"Nouveau nom\"]]\n",
    "                mapp_col[\"Colonne\"] = \"\"\n",
    "                mapp_col.reset_index(inplace=True, drop=True)\n",
    "                mapp_val = pd.DataFrame(columns=[\"Table\", \"Colonnes\", \"Valeurs actuelles\", \"Valeurs cible\"])\n",
    "                p=1\n",
    "                if mapp_col.empty == False:\n",
    "                    for i, val in enumerate(mapp_col.iterrows()):\n",
    "                        if str(mapp_col.at[i, \"Nouveau nom\"]) != \"nan\":\n",
    "                            mapp_col.at[i,\"Colonne\"] = mapp_col.at[i, \"Nouveau nom\"]\n",
    "                        else:\n",
    "                             mapp_col.at[i,\"Colonne\"] = mapp_col.at[i, \"Nom colonne\"]\n",
    "\n",
    "                    for i,val in enumerate(mapp_col[[\"Nom dimension\", \"Colonne\"]].iterrows()):\n",
    "\n",
    "                        if (self.dim[mapp_col.at[i, \"Nom dimension\"]][mapp_col.at[i, \"Colonne\"]]).empty == False:\n",
    "                            list_val = (self.dim[mapp_col.at[i, \"Nom dimension\"]][mapp_col.at[i, \"Colonne\"]]).unique()\n",
    "                            nom_col = mapp_col.at[i, \"Colonne\"]\n",
    "                            nom_table = mapp_col.at[i, \"Nom dimension\"]\n",
    "                        \n",
    "                        if len(list_val) != 0:\n",
    "                            for i, val in enumerate(list_val):                           \n",
    "                                mapp_val.at[p,\"Table\"] = nom_table\n",
    "                                mapp_val.at[p,\"Colonnes\"] = nom_col\n",
    "                                mapp_val.at[p,\"Valeurs actuelles\"] = val\n",
    "                                mapp_val.at[p,\"Valeurs cible\"] = \"\"\n",
    "                                p += 1\n",
    "\n",
    "                if mapp_val.empty: \n",
    "                    pass            \n",
    "                else:\n",
    "                    self.export_to_settings(mapp_val,\"Mapping données\")\n",
    "                    \n",
    "    def __compare__(self,sheet_name, cible_dataframe, excl_col= [], position=None):        \n",
    "        source = pd.read_excel(r'Settings & documentation\\Settings.xlsx', sheet_name=sheet_name)\n",
    "        source[\"compare\"] = \"\"\n",
    "        cible = cible_dataframe\n",
    "        cible[\"compare\"] = \"\"\n",
    "        colonnes_compared= [col for col in list(source.columns) if col not in excl_col]    \n",
    "        \n",
    "        for col in colonnes_compared:\n",
    "            source[\"compare\"] = source[\"compare\"] + source[col].astype('str')        \n",
    "        \n",
    "        for col in colonnes_compared:\n",
    "            cible[\"compare\"] = cible[\"compare\"] + cible[col].astype('str')\n",
    "        \n",
    "        to_keep = [line for line in list(source[\"compare\"]) if line in list(cible[\"compare\"])]\n",
    "        \n",
    "        to_add = [line for line in list(cible[\"compare\"]) if line not in list(source[\"compare\"])]\n",
    "        \n",
    "        result = source.loc[source[\"compare\"].isin(to_keep)]\n",
    "        \n",
    "        if to_add != \"\":\n",
    "            result = result.append(cible.loc[cible[\"compare\"].isin(to_add)])\n",
    "            \n",
    "        result.reset_index(drop=True, inplace=True)\n",
    "        result.drop([\"compare\"], axis=1, inplace=True)\n",
    "        return result\n",
    "        #self.export_to_settings(result,sheet_name,position)\n",
    "    \n",
    "    def update_fichier_source(self):\n",
    "        #Fonction mettant à jour l'onglet \"Fichiers Source\" du fichier Setting\n",
    "        \n",
    "        #Etape 1: skockage du nom des fichiers présents dans data        \n",
    "        all_dir = glob.glob(\"Data/*.csv\")    \n",
    "        all_files_name = [x[5:] for x in all_dir]\n",
    "        all_files_name = [x[:-4] for x in all_files_name]\n",
    "        df_files_col = pd.DataFrame()\n",
    "        p = 1\n",
    "\n",
    "        #Etape 2 lecture des fichiers présents dans data et extraction des noms des fichiers     \n",
    "        for dir in all_dir:\n",
    "            df = pd.read_csv(dir, encoding='utf-8', sep=';')\n",
    "\n",
    "            for i, col in enumerate(df.columns):\n",
    "                df_files_col.at[p, 'Nom fichier source'] = dir[5:-4]\n",
    "                df_files_col.at[p,'Nom champ source'] = col\n",
    "                df_files_col.at[p, 'Répertoire'] = dir\n",
    "                df_files_col.at[p, \"Date ajout\"] = \"\"\n",
    "                df_files_col.at[p, \"Date modification\"] = \"\"\n",
    "                p = p + i\n",
    "\n",
    "        df_dir_files = df_files_col.copy()\n",
    "        df_dir_files = df_dir_files[[\"Nom fichier source\", \"Répertoire\", \"Date ajout\", \"Date modification\"]].drop_duplicates()\n",
    "        result = self.__compare__(\"Fichiers Source\", df_dir_files, [\"Date ajout\", \"Date modification\"],0 )\n",
    "        result[\"Date ajout\"] = result[\"Date ajout\"].fillna(str(datetime.date(datetime.now())))\n",
    "        result[\"Date modification\"] = str(datetime.date(datetime.now()))\n",
    "        \n",
    "        self.export_to_settings(result,\"Fichiers Source\",0)\n",
    "        \n",
    "    def update_columns(self):\n",
    "        #Fonction mettant à jour l'onglet Mapping dim colonne suite à l'ajout des nouvelles dimensions\n",
    "        existing_colmap =  pd.read_excel(r\"Settings & documentation\\Settings.xlsx\", sheet_name='Mapping dim colonne') # Contient les valeurs de mapping dim colonne\n",
    "        fresh_col = pd.DataFrame(columns=[\"Nom dimension\", \"Nom colonne\"], data=[]) # Contient l'ensemble des nouvelles valeurs pour Mapping dim colonne\n",
    "        existing_colmap[\"Comparaison\"] = existing_colmap[\"Nom dimension\"] + existing_colmap[\"Nom colonne\"] # Création de la colonne \"Comparaison\" servant à comparer les lignes\n",
    "        to_keep = [] # Contient la liste des valeurs de la colonne \"Comparaison\" à conserver dans existing_colmap\n",
    "        to_add = [] # Contient la liste des valeurs de la colonne \"Comparaison\" à rajouter\n",
    "        p=0\n",
    "\n",
    "        for key, value in self.dim.items():\n",
    "\n",
    "            for i, col in enumerate(value.columns):\n",
    "                fresh_col.at[p, \"Nom dimension\"] = key\n",
    "                fresh_col.at[p, \"Nom colonne\"] = col\n",
    "                fresh_col.at[p, \"Nouveau nom\"] = \"\"\n",
    "                fresh_col.at[p, \"A mapper\"] = \"Non\"\n",
    "                p+=1\n",
    "\n",
    "        fresh_col[\"Comparaison\"] = fresh_col[\"Nom dimension\"] + fresh_col[\"Nom colonne\"]\n",
    "        to_keep = list(fresh_col[\"Comparaison\"])\n",
    "        existing_colmap = existing_colmap.loc[existing_colmap[\"Comparaison\"].isin(to_keep)]\n",
    "        existing_colmap.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # On détermine la liste des nouvelles valeurs absentes de la feuille de mapping\n",
    "\n",
    "        for val in to_keep:\n",
    "            if val in list(existing_colmap[\"Comparaison\"]):\n",
    "                pass\n",
    "\n",
    "            else:\n",
    "                to_add.append(val)\n",
    "\n",
    "        fresh_col = fresh_col.loc[fresh_col[\"Comparaison\"].isin(to_add)]\n",
    "        fresh_col.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        result = existing_colmap.append(fresh_col)\n",
    "\n",
    "        # On exporte le résultat dans l'onglet Mapping dim colonne de Setting\n",
    "        result = result.drop([\"Comparaison\"], axis=1)\n",
    "        result = result.sort_values([\"Nom dimension\", \"Nom colonne\"]) \n",
    "        self.export_to_settings(result, \"Mapping dim colonne\",2)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def update_map_val(self):       \n",
    "        mapp_col = pd.read_excel(r'Settings & documentation\\Settings.xlsx', sheet_name=\"Mapping dim colonne\")\n",
    "        mapp_col = mapp_col.loc[mapp_col[\"A mapper\"] == \"Oui\", [\"Nom dimension\", \"Nom colonne\", \"Nouveau nom\"]]\n",
    "        mapp_col[\"Colonne\"] = \"\"\n",
    "        mapp_col.reset_index(inplace=True, drop=True)\n",
    "        mapp_val = pd.DataFrame(columns=[\"Table\", \"Colonnes\", \"Valeurs actuelles\", \"Valeurs cible\"])\n",
    "        p=1\n",
    "        if mapp_col.empty == False:\n",
    "            for i, val in enumerate(mapp_col.iterrows()):\n",
    "                if str(mapp_col.at[i, \"Nouveau nom\"]) != \"nan\":\n",
    "                    mapp_col.at[i,\"Colonne\"] = mapp_col.at[i, \"Nouveau nom\"]\n",
    "                else:\n",
    "                     mapp_col.at[i,\"Colonne\"] = mapp_col.at[i, \"Nom colonne\"]\n",
    "        \n",
    "\n",
    "            for i,val in enumerate(mapp_col[[\"Nom dimension\", \"Colonne\"]].iterrows()):\n",
    "\n",
    "                if (self.dim[mapp_col.at[i, \"Nom dimension\"]][mapp_col.at[i, \"Colonne\"]]).empty == False:\n",
    "                    list_val = (self.dim[mapp_col.at[i, \"Nom dimension\"]][mapp_col.at[i, \"Colonne\"]]).unique()\n",
    "                    nom_col = mapp_col.at[i, \"Colonne\"]\n",
    "                    nom_table = mapp_col.at[i, \"Nom dimension\"]\n",
    "\n",
    "                if len(list_val) != 0:\n",
    "                    for i, val in enumerate(list_val):                           \n",
    "                        mapp_val.at[p,\"Table\"] = nom_table\n",
    "                        mapp_val.at[p,\"Colonnes\"] = nom_col\n",
    "                        mapp_val.at[p,\"Valeurs actuelles\"] = val\n",
    "                        mapp_val.at[p,\"Valeurs cible\"] = \"\"\n",
    "                        p += 1\n",
    "    \n",
    "        if mapp_val.empty: \n",
    "            pass     \n",
    "        else:\n",
    "            result = self.__compare__(\"Mapping données\", mapp_val)\n",
    "            self.export_to_settings(result,\"Mapping données\",3)        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cible = pd.read_excel(r'Settings & documentation\\Cible.xlsx', sheet_name= \"Fichiers Source\")\n",
    "#titi = Datamanagement()\n",
    "#toto = titi.compare(\"Fichiers Source\", cible, [\"Répertoire\"])\n",
    "#toto.to_excel(r'Settings & documentation\\Test.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Génération/Mise à jour du fichier setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:181: DeprecationWarning: Call to deprecated function get_sheet_names (Use wb.sheetnames).\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:184: DeprecationWarning: Call to deprecated function get_sheet_by_name (Use wb[sheetname]).\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:185: DeprecationWarning: Call to deprecated function remove_sheet (Use wb.remove(worksheet) or del wb[sheetname]).\n"
     ]
    }
   ],
   "source": [
    "my_data = Datamanagement()\n",
    "my_data.import_data()\n",
    "my_data.update_fichier_source()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Import des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 644 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### Ajouter les tables à intégrer ici\n",
    "tcw = my_data.import_csv('191119_TrainingCollectiveWishes.csv') # Demandes collectives non affectées à un plan de formation\n",
    "tiw = my_data.import_csv('191119_TrainingIndividualWishes.csv') # Demandes individuelles non affectées à un plan de formation\n",
    "tp = my_data.import_csv('191119_TrainingPlan.csv') # Plans de formation\n",
    "tpcw = my_data.import_csv('191119_TrainingPlanCollectiveWishes.csv') # Demande de formation collectives prises en charge dans un plan de formation\n",
    "tpiw = my_data.import_csv('191119_TrainingPlanIndividualWishes.csv') # Demande de formation individuelles prises en charge dans un plan de formation\n",
    "tr = my_data.import_csv('191119_TrainingRegister.csv') # Table recensant les inscription aux sessions de formation \n",
    "ts = my_data.import_csv('191119_TrainingSessions.csv') # Table recensant les sessions de formation \n",
    "tsc = my_data.import_csv('191119_TrainingStageCost.csv') # Table contenant les coûts des stages\n",
    "tsv2 = my_data.import_csv('191119_TrainingStagev2.csv') # Table contenant les stages\n",
    "emp = my_data.import_csv('191119_Employees.csv') # Table maître employé\n",
    "empc = my_data.import_csv('191119_EmployementContract.csv') # Table contrat employé\n",
    "indO = my_data.import_csv('191119_IndividualOrganization.csv') # Table organisation employé\n",
    "indpp =my_data.import_csv('191119_IndivPPCsNew.csv') # ?\n",
    "#setting = pd.read_excel(r'Data/Settings.xlsx', sheets=\"Mapp_data\") # Table de paramétrage servant à mapper les données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Renommage des clés fonctionnelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 44 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ts = my_data.update_key({'clientcode':'SessionID', 'coursecode':'FormationID', 'startdate':'SessionDate'},'191119_TrainingSessions')\n",
    "tsv2 = my_data.update_key({'clientcode':'SessionID'},'191119_TrainingStagev2')\n",
    "tr = my_data.update_key({'clientcode':'SessionID', 'traineusername':'USERNAME','trainingplanclientcode':'PlanID', 'trainingwishclientcode':'WishID'}, '191119_TrainingRegister')\n",
    "tp = my_data.update_key({'plancode':'PlanID'}, '191119_TrainingPlan')\n",
    "emp = my_data.update_key({'username':'USERNAME'}, '191119_Employees')\n",
    "tcw = my_data.update_key({'clientcode':'WishID','coursecode':'FormationID','username':'USERNAME'}, '191119_TrainingCollectiveWishes')\n",
    "tiw = my_data.update_key({'username':'USERNAME', 'employeenumber':'ZY00.MATCLE', 'clientcode':'WishID', 'coursecode':'FormationID'},'191119_TrainingIndividualWishes')\n",
    "tpcw = my_data.update_key({'plan_code':'PlanID', 'wish_code':'WishID'}, '191119_TrainingPlanCollectiveWishes')\n",
    "tpiw = my_data.update_key({'plan_code':'PlanID', 'wish_code':'WishID'} ,'191119_TrainingPlanIndividualWishes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Alimentation des dictionnaires contenant les colonnes et dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "my_dict_dataframe = {\"tcw\": tcw, \"tiw\": tiw, \"tp\" : tp, \"tpcw\" : tpcw, \"tr\" : tr, \"ts\" : ts, \"tsc\" : tsc, \"tsv2\" : tsv2, \"emp\" : emp,\n",
    "           \"empc\" : empc, \"indO\": indO, \"indpp\": indpp}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Creation des tables de dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de la table dimension demandes de formations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 53 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Génération de la table de dimension Souhaits de formation à partir des tables 191119_TrainingCollectiveWishes et 191119_TrainingIndividualWishes \n",
    "dim_wish = tcw.append(tiw,sort=True)\n",
    "dim_wish.reset_index(drop=True, inplace=True)\n",
    "dim_wish[\"Wish_key\"] = dim_wish.index\n",
    "dim_wish.loc[dim_wish.nbtrainees.isna(), \"nbtrainees\"] = 1\n",
    "dim_wish.index.name=\"key_wish\"\n",
    "my_data.import_dim(\"Souhaits de formation\", dim_wish)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de la table dimension plan de formation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Génération de la table plan de formation\n",
    "dim_plan = tp\n",
    "\n",
    "# On ajoute une clé technique à la table dim_plan\n",
    "dim_plan[\"key_plan\"] = dim_plan.index\n",
    "\n",
    "# On insère une ligne pour affecter par la suite les demandes non affectées à une clé plan\n",
    "empty_data = {\"PlanID\" : [\"Pas de plan\"], \"key_plan\" : [9999]}\n",
    "empty_plan = pd.DataFrame(data=empty_data)\n",
    "dim_plan= dim_plan.append(empty_plan,ignore_index=True)\n",
    "\n",
    "my_data.import_dim(\"Plan de formation\", dim_plan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traitement du mapping des colonnes et des valeurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:181: DeprecationWarning: Call to deprecated function get_sheet_names (Use wb.sheetnames).\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:184: DeprecationWarning: Call to deprecated function get_sheet_by_name (Use wb[sheetname]).\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:185: DeprecationWarning: Call to deprecated function remove_sheet (Use wb.remove(worksheet) or del wb[sheetname]).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nom_col\n",
      "planname\n",
      "table\n",
      "Plan de formation\n",
      "nom_col\n",
      "state\n",
      "table\n",
      "Plan de formation\n",
      "Wall time: 6.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Verification si la colonne Mapping dim existe dans le fichier setting, si non on va la créer\n",
    "try:\n",
    "    pd.read_excel(r'Settings & documentation\\Settings.xlsx', sheet_name=\"Mapping dim colonne\")   \n",
    "    Mapp_sheet = True    \n",
    "except:\n",
    "    Mapp_sheet = False\n",
    "    \n",
    "    \n",
    "if Mapp_sheet == True:\n",
    "    #update_sheet_mapcol(my_data.dim)\n",
    "    my_data.update_columns()\n",
    "    pass\n",
    "else:    \n",
    "    #add_sheet_mapcol(my_data.dim)\n",
    "    my_data.add_sheet_mapcol()\n",
    "\n",
    "my_data.map_col()\n",
    "#my_data.dim = map_col(my_data.dim)\n",
    "\n",
    "my_data.mapp_data()\n",
    "\n",
    "try:\n",
    "    pd.read_excel(r'Settings & documentation\\Settings.xlsx', sheet_name=\"Mapping données\")   \n",
    "    Mapp_val = True    \n",
    "except:\n",
    "    Mapp_val = False\n",
    "    \n",
    "if Mapp_val == True :\n",
    "    my_data.update_map_val()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Création des tables de fait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table de fait souhaits de formation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 130 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Création des indicateurs de fomation prévisionnelle, ces derniers s'appuient sur les 4 tables liées aux souhaits de formation\n",
    "#Grain = 1 ligne correspond à un souhait de formation\n",
    "\n",
    "# Les tables contenant l'ensemble des souhaits de formation 191119_TrainingCollectiveWishes et 191119_TrainingIndividualWishes vont être fusionnées dans la table wish_all\n",
    "# Seules les clés externes et les attributs servant au calcule des indicateurs seront conservés\n",
    "# La table 191119_TrainingIndividualWishes ne contenant pas l'indicateur \"nbtrainees\", nous considérons qu'une ligne équivaut à 1 nbtrainees\n",
    "\n",
    "tcw_staging = tcw.copy()\n",
    "tcw_staging = tcw_staging[[\"WishID\",\"employeenumber\", \"FormationID\", \"nbtrainees\", \"nbmen\", \"nbwomen\"]]\n",
    "tiw_staging = tiw.copy()\n",
    "tiw_staging = tiw_staging[[\"WishID\", \"ZY00.MATCLE\",\"FormationID\"]]\n",
    "tiw_staging[\"nbtrainees\"]=1\n",
    "\n",
    "wish_all = tcw_staging.append(tiw_staging)\n",
    "\n",
    "# Les tables contenant les demandes de formation associées à un plan vont être fusionnées\n",
    "# Etape 1 récupérer les tables 191119_TrainingPlanCollectiveWishes et 191119_TrainingPlanIndividualWishes correspondant aux souhaits de formation associés à des plans\n",
    "# Etape 2 on va supprimer les champs descriptifs: action, default_currency,hourly_wage_rage\n",
    "# Etape 3 on fusionne les tables dans la table wish_plan\n",
    "\n",
    "tpcw_staging = tpcw.copy()\n",
    "tpcw_staging = tpcw_staging.drop(columns=[\"action\", \"default_currency\",\"hourly_wage_rate\", \"training_system\"])\n",
    "tpiw_staging = tpiw.copy()\n",
    "tpiw_staging = tpiw_staging.drop(columns=[\"action\", \"default_currency\", \"training_system\"])\n",
    "\n",
    "wish_plan = tpcw_staging.copy()\n",
    "wish_plan = wish_plan.append(tpiw_staging)\n",
    "\n",
    "# On fusionne les 2 tables créées afin de créer la table de fait wish_fact\n",
    "\n",
    "wish_fact = pd.merge(wish_all, wish_plan, on = \"WishID\", how='left')\n",
    "wish_fact.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# On ajoute la clé technique de la table plan de formation\n",
    "\n",
    "wish_fact = pd.merge(wish_fact, dim_plan[['PlanID','key_plan']], on='PlanID', how='left')\n",
    "\n",
    "# On ajoute l'indicateur in_plan\n",
    "wish_fact[\"In_plan\"] = \"\"\n",
    "wish_fact.loc[wish_fact['key_plan'].isna() == True,\"In_plan\"] = 0\n",
    "wish_fact.loc[wish_fact['key_plan'].isna() == False,\"In_plan\"] = 1\n",
    "\n",
    "# Typage des valeurs\n",
    "wish_fact[\"wage_cost\"] = wish_fact[\"wage_cost\"].str.replace(\",\",\".\", regex=True)\n",
    "\n",
    "wish_fact[\"wage_cost\"] = wish_fact[\"wage_cost\"].astype('float64')\n",
    "wish_fact[\"key_plan\"] = wish_fact[\"key_plan\"].fillna(9999)\n",
    "wish_fact[\"key_plan\"] = wish_fact[\"key_plan\"].astype('int64')\n",
    "\n",
    "\n",
    "# Stockage dans my_data de la table wish_fact \n",
    "\n",
    "my_data.import_fact(\"Indicateurs Prévisonnels\", wish_fact)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table de faits des formations suivi du plan de formation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Préparation de la table de fait contenant les indicateurs liés au suivi du plan\n",
    "#\n",
    "tr_staging = tr.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export des données vers le répertoire Transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 990 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#for key, value in my_dict_dataframe.items():\n",
    " #       location = \"Transformed data\"\n",
    "  #      file_name = str(key) + '.csv'\n",
    "   #     location = os.path.join(location, file_name)  \n",
    "    #    value.to_csv(location, encoding='utf16', index=False)\n",
    "    \n",
    "my_data.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"En cours d'élaboration\" 'Validé' nan]\n"
     ]
    }
   ],
   "source": [
    "print(my_data.dim[\"Plan de formation\"][\"state\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
