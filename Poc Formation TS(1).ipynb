{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POC Power BI TS Formation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from os import path\n",
    "import glob\n",
    "import xlsxwriter\n",
    "import openpyxl "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Déclaration des fonctions exploitées dans le code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Génération/Mise à jour du fichier setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data():\n",
    "    all_dir = glob.glob(\"Data/*.csv\")    \n",
    "    all_files_name = [x[5:] for x in all_dir]\n",
    "    all_files_name = [x[:-4] for x in all_files_name]\n",
    "    df_files_col = pd.DataFrame()\n",
    "    p = 1\n",
    "    \n",
    "    for dir in all_dir:\n",
    "        df = pd.read_csv(dir, encoding='utf-8', sep=';')\n",
    "        \n",
    "        for i, col in enumerate(df.columns):\n",
    "            df_files_col.at[p, 'Nom fichier source'] = dir[5:-4]\n",
    "            df_files_col.at[p,'Nom champ source'] = col\n",
    "            df_files_col.at[p,'Type'] = str(df[col].dtypes)\n",
    "            df_files_col.at[p,'Synthèse'] = str(df[col].describe())\n",
    "            df_files_col.at[p, 'Répertoire'] = dir\n",
    "            p = p + i\n",
    "    \n",
    "    df_dir_files = df_files_col.copy()\n",
    "    df_dir_files = df_dir_files[[\"Nom fichier source\", \"Répertoire\"]].drop_duplicates()\n",
    "    \n",
    "    if path.exists(\"Settings & documentation\\Settings.xlsx\"):\n",
    "        pass\n",
    "\n",
    "    else:\n",
    "\n",
    "        writer = pd.ExcelWriter(r\"Settings & documentation\\Settings.xlsx\", engine='xlsxwriter')\n",
    "        workbook  = writer.book\n",
    "        df_dir_files.to_excel(writer, sheet_name='Fichiers Source', index=False)\n",
    "        \n",
    "        df_files_col[['Nom fichier source', 'Nom champ source', 'Type', 'Synthèse' ]].to_excel(writer, sheet_name='Fichiers et colonnes source', index=False)\n",
    "                \n",
    "        worksheet_FCS = writer.sheets[\"Fichiers et colonnes source\"]\n",
    "        worksheet_FS = writer.sheets[\"Fichiers Source\"]\n",
    "        worksheet1 = workbook.add_worksheet(\"Mapping données\")\n",
    "        \n",
    "        cell_format_FCS = workbook.add_format() \n",
    "        cell_format_FCS.set_text_wrap()\n",
    "        cell_format_FCS.set_align('center')\n",
    "        cell_format_FCS.set_align('vcenter')\n",
    "        \n",
    "        cell_format_FS = workbook.add_format()    \n",
    "        cell_format_FS.set_align('left')\n",
    "                \n",
    "        worksheet_FCS.set_column('A:B', 30, cell_format_FCS)\n",
    "        worksheet_FCS.set_column('C:C', 15, cell_format_FCS)\n",
    "        worksheet_FCS.set_column('D:D', 25, cell_format_FCS)\n",
    "        worksheet_FS.set_column('A:A', 40, cell_format_FS)\n",
    "        worksheet_FS.set_column('B:B', 60, cell_format_FS)\n",
    "\n",
    "        writer.save()\n",
    "        workbook.close()\n",
    "\n",
    "# Fonction créant la feuille Mapping dim dans le fichier Settings\n",
    "# Cette feuille contient l'ensemble des valeurs de dimension et permet de réaliser un mapping pour changer le nom des attributs\n",
    "\n",
    "def add_sheet_mapcol(DicDataframe):\n",
    "    \n",
    "    df = pd.DataFrame(columns=[\"Nom dimension\", \"Nom colonne\"],data=[])\n",
    "    \n",
    "    for key, value in DicDataframe.items():        \n",
    "        if len(key) >= 3:\n",
    "            if key[:3] == \"dim\":\n",
    "                for i, col in enumerate(value.columns):\n",
    "                    df.at[i, \"Nom dimension\"] = key\n",
    "                    df.at[i, \"Nom colonne\"] = col\n",
    "                    df.at[i, \"Nouveau_nom\"] = \"\"\n",
    "                    df.at[i, \"A mapper\"] = \"Non\"                \n",
    "      \n",
    "    workbook1 = openpyxl.load_workbook(r\"Settings & documentation\\Settings.xlsx\")  \n",
    "    writer = pd.ExcelWriter(r\"Settings & documentation\\Settings.xlsx\", engine='openpyxl')\n",
    "    writer.book = workbook1\n",
    "    df.to_excel(writer, sheet_name=\"Mapping dim colonne\",engine='openpyxl',index=False)     \n",
    "    writer.save()\n",
    "    writer.close()\n",
    "    \n",
    "    workbook1 = openpyxl.load_workbook(r\"Settings & documentation\\Settings.xlsx\")\n",
    "    writer = pd.ExcelWriter(r\"Settings & documentation\\Settings.xlsx\", engine='openpyxl')\n",
    "    writer.book = workbook1\n",
    "    workbook1[\"Mapping dim colonne\"].column_dimensions[\"A\"].width = 20\n",
    "    workbook1[\"Mapping dim colonne\"].column_dimensions[\"B\"].width = 20\n",
    "    workbook1[\"Mapping dim colonne\"].column_dimensions[\"C\"].width = 20\n",
    "    \n",
    "    writer.save()\n",
    "    writer.close()\n",
    "    \n",
    "import_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction mapping des noms de colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction transformant le nom des colonnes suivant le mapping effectué dans l'onglet Mapping dim colonne\n",
    "# Entrée: Dictionnaire key: Nom dataframe  Value : Dataframe\n",
    "# Sortie un dictionnaire \"nom\"/Dataframe avec les valeurs des colonnes actualisées suivant l'onglet de mapping \"Mapping dim colonne\" du fichier settings\n",
    "\n",
    "def map_col(dict_dataframe):\n",
    "    md = pd.read_excel(r\"Settings & documentation\\Settings.xlsx\", sheet_name=\"Mapping dim colonne\")\n",
    "    mdf = md[\"Nom dimension\"].unique()\n",
    "    dic_map = {}\n",
    "    for dim in mdf:\n",
    "        map = md.loc[(md[\"Nom dimension\"] == dim ) & (md[\"Nouveau nom\"].notnull()== True),[\"Nom colonne\",\"Nouveau nom\"]]\n",
    "        map.reset_index(drop=True, inplace=True)\n",
    "            \n",
    "        for i, val in enumerate(map.iterrows()):           \n",
    "            dict_dataframe[dim].rename(columns={map.at[i, \"Nom colonne\"]:map.at[i,\"Nouveau nom\"]},inplace=True)\n",
    "            \n",
    "    return dict_dataframe            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapp_data(dict_dataframe):\n",
    "    to_mapp_data = pd.read_excel(r'Settings & documentation\\Settings.xlsx', sheet_name=\"Mapping données\")\n",
    "\n",
    "    if to_mapp_data.empty == True:\n",
    "        mapp_col = pd.read_excel(r'Settings & documentation\\Settings.xlsx', sheet_name=\"Mapping dim colonne\")\n",
    "        mapp_col = mapp_col.loc[mapp_col[\"A mapper\"] == \"Oui\", [\"Nom dimension\", \"Nom colonne\", \"Nouveau nom\"]]\n",
    "        mapp_col[\"Colonne\"] = \"\"\n",
    "        mapp_col.reset_index(inplace=True, drop=True)\n",
    "        \n",
    "\n",
    "        if mapp_col.empty == False:\n",
    "            for i, val in enumerate(mapp_col.iterrows()):\n",
    "                if str(mapp_col.at[i, \"Nouveau nom\"]) != \"nan\":\n",
    "                    mapp_col.at[i,\"Colonne\"] = mapp_col.at[i, \"Nouveau nom\"]\n",
    "                else:\n",
    "                     mapp_col.at[i,\"Colonne\"] = mapp_col.at[i, \"Nom colonne\"]\n",
    "           \n",
    "            for i,val in enumerate(mapp_col[[\"Nom dimension\", \"Colonne\"]].iterrows()):\n",
    "                if to_mapp_data.empty == True:\n",
    "                    if (dict_dataframe[mapp_col.at[i, \"Nom dimension\"]][mapp_col.at[i, \"Colonne\"]]).empty == False:\n",
    "                        #print(mapp_col.at[i, \"Nom dimension\"])\n",
    "                        #print(dict_dataframe[mapp_col.at[i, \"Nom dimension\"]][mapp_col.at[i, \"Colonne\"]])\n",
    "                        #(dict_dataframe[mapp_col.at[i, \"Nom dimension\"]][mapp_col.at[i, \"Colonne\"]]).unique()\n",
    "                        list_val = (dict_dataframe[mapp_col.at[i, \"Nom dimension\"]][mapp_col.at[i, \"Colonne\"]]).unique()\n",
    "                        #val_2 = [x for x in val if str(x) != 'nan']\n",
    "                        #list_val = val_2\n",
    "                        \n",
    "                        print(list_val)\n",
    "                        #print(\"hfhfjfdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Import des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 125 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### Ajouter les tables à intégrer ici\n",
    "tcw = pd.read_csv(r'Data/TrainingCollectiveWishes.csv', engine=None,encoding='utf-8', sep=';') # Demandes collectives non affectées à un plan de formation\n",
    "tiw = pd.read_csv(r'Data/TrainingIndividualWishes.csv', engine=None,encoding='utf-8', sep=';') # Demandes individuelles non affectées à un plan de formation\n",
    "tp = pd.read_csv(r'Data/TrainingPlan.csv', engine=None,encoding='utf-8', sep=';') # Plans de formation\n",
    "tpcw = pd.read_csv(r'Data/TrainingPlanCollectiveWishes.csv', engine=None,encoding='utf-8', sep=';') # Demande de formation collectives prises en charge dans un plan de formation\n",
    "tpci = pd.read_csv(r'Data/TrainingPlanIndividualWishes.csv', engine=None,encoding='utf-8', sep=';') # Demande de formation individuelles prises en charge dans un plan de formation\n",
    "tr = pd.read_csv(r'Data/TrainingRegister.csv', engine=None,encoding='utf-8', sep=';') # Table recensant les inscription aux sessiosn de formation \n",
    "ts = pd.read_csv(r'Data/TrainingSessions.csv', engine=None,encoding='utf-8', sep=';') # Table recensant les sessions de formation \n",
    "tsc = pd.read_csv(r'Data/TrainingStageCost.csv', engine=None,encoding='utf-8', sep=';') # Table contenant les coûts des stages\n",
    "tsv2 = pd.read_csv(r'Data/TrainingStagev2.csv', engine=None,encoding='utf-8', sep=';') # Table contenant les stages\n",
    "emp = pd.read_csv(r'Data/Employees.csv', engine=None,encoding='utf-8', sep=';') # Table maître employé\n",
    "empc = pd.read_csv(r'Data/EmployementContract.csv', engine=None,encoding='utf-8', sep=';') # Table contrat employé\n",
    "indO = pd.read_csv(r'Data/IndividualOrganization.csv', engine=None,encoding='utf-8', sep=';') # Table organisation employé\n",
    "indpp = pd.read_csv(r'Data/IndivPPCsNew.csv', engine=None,encoding='utf-8', sep=';') # ?\n",
    "#setting = pd.read_excel(r'Data/Settings.xlsx', sheets=\"Mapp_data\") # Table de paramétrage servant à mapper les données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Renommage des clés fonctionnelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ts.rename(columns={'clientcode':'SessionID', 'coursecode':'FormationID', 'startdate':'SessionDate'},inplace=True)\n",
    "tsv2.rename(columns={'clientcode':'SessionID'},inplace=True)\n",
    "tr.rename(columns={'clientcode':'SessionID', 'traineusername':'USERNAME'},inplace=True)\n",
    "tp.rename(columns={'plancode':'PlanID'},inplace=True)\n",
    "emp.rename(columns={'username':'USERNAME'}, inplace=True)\n",
    "tcw.rename(columns={'clientcode':'WishID','coursecode':'FormationID','username':'USERNAME'},inplace=True)\n",
    "tiw.rename(columns={'username':'USERNAME', 'employeenumber':'ZY00.MATCLE', 'clientcode':'WishID', 'coursecode':'FormationID'},inplace=True)\n",
    "tpcw.rename(columns={'plan_code':'PlanID', 'wish_code':'WishID'}, inplace=True)\n",
    "tpci.rename(columns={'plan_code':'PlanID', 'wish_code':'WishID'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Alimentation des dictionnaires contenant les colonnes et dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#my_dict_columns = {\"tcw\": tcw.columns, \"tiw\": tiw.columns, \"tp\" : tp.columns, \"tpcw\" : tpcw.columns, \"tr\" : tr.columns, \"ts\" : ts.columns, \"tsc\" : tsc.columns, \"tsv2\" : tsv2.columns, \"emp\" : emp.columns,\n",
    " #          \"empc\" : empc.columns, \"indO\": indO.columns, \"indpp\": indpp.columns}\n",
    "\n",
    "my_dict_dataframe = {\"tcw\": tcw, \"tiw\": tiw, \"tp\" : tp, \"tpcw\" : tpcw, \"tr\" : tr, \"ts\" : ts, \"tsc\" : tsc, \"tsv2\" : tsv2, \"emp\" : emp,\n",
    "           \"empc\" : empc, \"indO\": indO, \"indpp\": indpp}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Creation des tables de dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de la table dimension demandes de formations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 31.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dim_wish = tcw.append(tiw,sort=True)\n",
    "dim_wish.reset_index(drop=True, inplace=True)\n",
    "dim_wish[\"Wish_key\"] = dim_wish.index\n",
    "dim_wish.loc[dim_wish.nbtrainees.isna(), \"nbtrainees\"] = 1\n",
    "#dim_wish = df_mapp(dim_wish)\n",
    "my_dict_dataframe[\"dim_wish_table\"]= dim_wish\n",
    "#wish_table.to_excel(r'Transformed data\\wish_table.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traitement du mapping des colonnes et des valeurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['tcw', 'tiw', 'tp', 'tpcw', 'tr', 'ts', 'tsc', 'tsv2', 'emp', 'empc', 'indO', 'indpp', 'dim_wish_table'])\n",
      "[nan 'Medium' 'Important' 'Low']\n",
      "['TS_DEVELOPPEMENT' 'TS_MANAGERREQUEST' \"Campagne d'entretiens annuels\"\n",
      " 'Yearly appraisals' 'MY_TS' 'My Space' 'TS_EVALUATION' 'Bewertungsrunde'\n",
      " 'Campagne de Recueil des besoins formation' 'TALENT_REVIEW'\n",
      " 'Entretiens annuels' 'Fuera de campaña' 'Utvecklingssamtal'\n",
      " 'Medarbetarsamtal' 'Utanför kampanj' 'Utvecklingssamtal 2013' 'MUS 2016'\n",
      " 'Medarbejdersamtaler' 'MUS 2017' 'Entrevistas anuales'\n",
      " 'TS|Campaign|Label|TR_Campaign' 'Mitarbeitergespräch 2019'\n",
      " 'TS|Campaign|Label|PR']\n",
      "Wall time: 437 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "try:\n",
    "    pd.read_excel(r'Settings & documentation\\Settings.xlsx', sheet_name=\"Mapping dim colonne\")\n",
    "    Mapp_sheet = True    \n",
    "except:\n",
    "    Mapp_sheet = False\n",
    "    \n",
    "if Mapp_sheet == True:    \n",
    "    pass\n",
    "else:\n",
    "    add_sheet_mapcol(my_dict_dataframe)\n",
    "\n",
    "my_dict_dataframe = map_col(my_dict_dataframe)\n",
    "\n",
    "print(my_dict_dataframe.keys())\n",
    "mapp_data(my_dict_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan 'Medium' 'Important' 'Low']\n"
     ]
    }
   ],
   "source": [
    "print(my_dict_dataframe[\"dim_wish_table\"][\"priorité\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Création des tables de fait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table de fait demande de formation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wish_fact' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'wish_fact' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dim_wish = dim_wish[[\"Wish_key\", \"nbtrainees\"]].copy()\n",
    "dim_wish.loc[:, \"Nb_demandes\"]= 1\n",
    "\n",
    "my_dict_dataframe[\"wish_fact\"] = wish_fact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export des données vers le répertoire Transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 624 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for key, value in my_dict_dataframe.items():\n",
    "        location = \"Transformed data\"\n",
    "        file_name = str(key) + '.csv'\n",
    "        location = os.path.join(location, file_name)  \n",
    "        value.to_csv(location, encoding='utf16', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
